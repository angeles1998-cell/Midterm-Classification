{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3943de86-52c6-4109-a92a-5c2323dde733",
   "metadata": {},
   "source": [
    "## Data loading and initial exploration"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "id": "e90c6c69-24bb-42b0-94e3-982bdcdbefc0",
   "metadata": {},
=======
   "execution_count": 32,
   "id": "e90c6c69-24bb-42b0-94e3-982bdcdbefc0",
   "metadata": {
    "scrolled": true
   },
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 32,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from CSV file\n",
    "df = pd.read_csv(\"../Data/raw/student-mat.csv\", sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 34,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "7e24c1f0-ff00-4a22-844b-8bfc7bcf4b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   school      395 non-null    object\n",
      " 1   sex         395 non-null    object\n",
      " 2   age         395 non-null    int64 \n",
      " 3   address     395 non-null    object\n",
      " 4   famsize     395 non-null    object\n",
      " 5   Pstatus     395 non-null    object\n",
      " 6   Medu        395 non-null    int64 \n",
      " 7   Fedu        395 non-null    int64 \n",
      " 8   Mjob        395 non-null    object\n",
      " 9   Fjob        395 non-null    object\n",
      " 10  reason      395 non-null    object\n",
      " 11  guardian    395 non-null    object\n",
      " 12  traveltime  395 non-null    int64 \n",
      " 13  studytime   395 non-null    int64 \n",
      " 14  failures    395 non-null    int64 \n",
      " 15  schoolsup   395 non-null    object\n",
      " 16  famsup      395 non-null    object\n",
      " 17  paid        395 non-null    object\n",
      " 18  activities  395 non-null    object\n",
      " 19  nursery     395 non-null    object\n",
      " 20  higher      395 non-null    object\n",
      " 21  internet    395 non-null    object\n",
      " 22  romantic    395 non-null    object\n",
      " 23  famrel      395 non-null    int64 \n",
      " 24  freetime    395 non-null    int64 \n",
      " 25  goout       395 non-null    int64 \n",
      " 26  Dalc        395 non-null    int64 \n",
      " 27  Walc        395 non-null    int64 \n",
      " 28  health      395 non-null    int64 \n",
      " 29  absences    395 non-null    int64 \n",
      " 30  G1          395 non-null    int64 \n",
      " 31  G2          395 non-null    int64 \n",
      " 32  G3          395 non-null    int64 \n",
      "dtypes: int64(16), object(17)\n",
      "memory usage: 102.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# General information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 19,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "2e70caa8-49bd-47e7-aac8-df9cbf2b123d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.696203</td>\n",
       "      <td>2.749367</td>\n",
       "      <td>2.521519</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.334177</td>\n",
       "      <td>3.944304</td>\n",
       "      <td>3.235443</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>1.481013</td>\n",
       "      <td>2.291139</td>\n",
       "      <td>3.554430</td>\n",
       "      <td>5.708861</td>\n",
       "      <td>10.908861</td>\n",
       "      <td>10.713924</td>\n",
       "      <td>10.415190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.276043</td>\n",
       "      <td>1.094735</td>\n",
       "      <td>1.088201</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.890741</td>\n",
       "      <td>1.287897</td>\n",
       "      <td>1.390303</td>\n",
       "      <td>8.003096</td>\n",
       "      <td>3.319195</td>\n",
       "      <td>3.761505</td>\n",
       "      <td>4.581443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean    16.696203    2.749367    2.521519    1.448101    2.035443    0.334177   \n",
       "std      1.276043    1.094735    1.088201    0.697505    0.839240    0.743651   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    3.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     3.944304    3.235443    3.108861    1.481013    2.291139    3.554430   \n",
       "std      0.896659    0.998862    1.113278    0.890741    1.287897    1.390303   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    3.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "         absences          G1          G2          G3  \n",
       "count  395.000000  395.000000  395.000000  395.000000  \n",
       "mean     5.708861   10.908861   10.713924   10.415190  \n",
       "std      8.003096    3.319195    3.761505    4.581443  \n",
       "min      0.000000    3.000000    0.000000    0.000000  \n",
       "25%      0.000000    8.000000    9.000000    8.000000  \n",
       "50%      4.000000   11.000000   11.000000   11.000000  \n",
       "75%      8.000000   13.000000   13.000000   14.000000  \n",
       "max     75.000000   19.000000   19.000000   20.000000  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 14,
=======
     "execution_count": 19,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Basic statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 36,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "08fa8a71-e983-4061-b33b-714586768b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns 'object'\n",
    "categorical_columns = df.select_dtypes(include = ['object']).columns.tolist()\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 38,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "6ff2e240-6848-4725-8b35-c1e615a407c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school        0\n",
       "sex           0\n",
       "age           0\n",
       "address       0\n",
       "famsize       0\n",
       "Pstatus       0\n",
       "Medu          0\n",
       "Fedu          0\n",
       "Mjob          0\n",
       "Fjob          0\n",
       "reason        0\n",
       "guardian      0\n",
       "traveltime    0\n",
       "studytime     0\n",
       "failures      0\n",
       "schoolsup     0\n",
       "famsup        0\n",
       "paid          0\n",
       "activities    0\n",
       "nursery       0\n",
       "higher        0\n",
       "internet      0\n",
       "romantic      0\n",
       "famrel        0\n",
       "freetime      0\n",
       "goout         0\n",
       "Dalc          0\n",
       "Walc          0\n",
       "health        0\n",
       "absences      0\n",
       "G1            0\n",
       "G2            0\n",
       "G3            0\n",
       "dtype: int64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 20,
=======
     "execution_count": 38,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b3ce6-dd2b-4db5-b002-192f3ad68c24",
   "metadata": {},
   "source": [
    "## Preprocessing code"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 40,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "a763b636-8624-4667-b055-feb62cd1e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 42,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "f551f758-b649-4628-8ee2-5e3454791a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the binary classification target variable: pass = 1 if G3 >= 10, else 0\n",
    "df['pass'] = df['G3'].apply(lambda x: 1 if x >= 10 else 0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": 44,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "aa215eca-bf53-4d62-9345-497223f380be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  \\\n",
      "0     18     4     4           2          2         0       4         3   \n",
      "1     17     1     1           1          2         0       5         3   \n",
      "2     15     1     1           1          2         3       4         3   \n",
      "3     15     4     2           1          3         0       3         2   \n",
      "4     16     3     3           1          2         0       4         3   \n",
      "..   ...   ...   ...         ...        ...       ...     ...       ...   \n",
      "390   20     2     2           1          2         2       5         5   \n",
      "391   17     3     1           2          1         0       2         4   \n",
      "392   21     1     1           1          1         3       5         5   \n",
      "393   18     3     2           3          1         0       4         4   \n",
      "394   19     1     1           1          1         0       3         2   \n",
      "\n",
      "     goout  Dalc  ...  guardian_mother  guardian_other  schoolsup_yes  \\\n",
      "0        4     1  ...                1               0              1   \n",
      "1        3     1  ...                0               0              0   \n",
      "2        2     2  ...                1               0              1   \n",
      "3        2     1  ...                1               0              0   \n",
      "4        2     1  ...                0               0              0   \n",
      "..     ...   ...  ...              ...             ...            ...   \n",
      "390      4     4  ...                0               1              0   \n",
      "391      5     3  ...                1               0              0   \n",
      "392      3     3  ...                0               1              0   \n",
      "393      1     3  ...                1               0              0   \n",
      "394      3     3  ...                0               0              0   \n",
      "\n",
      "     famsup_yes  paid_yes  activities_yes  nursery_yes  higher_yes  \\\n",
      "0             0         0               0            1           1   \n",
      "1             1         0               0            0           1   \n",
      "2             0         1               0            1           1   \n",
      "3             1         1               1            1           1   \n",
      "4             1         1               0            1           1   \n",
      "..          ...       ...             ...          ...         ...   \n",
      "390           1         1               0            1           1   \n",
      "391           0         0               0            0           1   \n",
      "392           0         0               0            0           1   \n",
      "393           0         0               0            0           1   \n",
      "394           0         0               0            1           1   \n",
      "\n",
      "     internet_yes  romantic_yes  \n",
      "0               0             0  \n",
      "1               1             0  \n",
      "2               1             0  \n",
      "3               1             1  \n",
      "4               0             0  \n",
      "..            ...           ...  \n",
      "390             0             0  \n",
      "391             1             0  \n",
      "392             0             0  \n",
      "393             1             0  \n",
      "394             1             0  \n",
      "\n",
      "[395 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical columns\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "df_encoded = df_encoded.astype(int)\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 46,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "f70d54bb-154c-459e-ab0b-85500dce182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features A, B, and C\n",
    "# uses G1 and G2\n",
    "features_A = df_encoded.drop(columns=['G3', 'pass']) \n",
    "# without G2\n",
    "features_B = features_A.drop(columns=['G2'])       \n",
    "# without G1\n",
    "features_C = features_B.drop(columns=['G1'])         "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 50,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "da75d41e-3e8f-4fb8-8123-43c04ceb7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target\n",
    "target = df_encoded['pass']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6458f4-5ff8-4525-8c96-7885ec1da388",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 49,
=======
   "execution_count": 52,
>>>>>>> 0378e5c (Primer commit - notebook with models.)
   "id": "18578315-9e78-4e98-8056-e13f1239acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_A_scaled = scaler.fit_transform(features_A)\n",
    "X_B_scaled = scaler.fit_transform(features_B)\n",
    "X_C_scaled = scaler.fit_transform(features_C)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "id": "af90b88a-72a6-4e95-af08-5dbcb70e4734",
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "cell_type": "markdown",
   "id": "c618aa1f-ab67-4ad6-b7d3-e968d16a569a",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Continuation of the project\n",
    "\n",
    "This notebook builds upon the work previously done by Wendy, who handled data loading, cleaning, encoding, and feature scaling.\n",
    "\n",
    "Starting from that preprocessed data, the following sections include:\n",
    "\n",
    "- Implementation of four classification models: Decision Tree, Random Forest, SVM, and Neural Network\n",
    "- Evaluation of model performance across different feature sets (A, B, C)\n",
    "- Additional contributions and experiments conducted by Ãngeles Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb6b4f-bb4b-4cb6-ae31-2b3418c1e6c7",
   "metadata": {},
   "source": [
    "## ðŸ”¸ Classification Models (Ãngeles)\n",
    "\n",
    "This section trains and evaluates four classification algorithms on datasets A, B, and C using 10-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "385542f8-a2ef-420c-87c0-3f48b5f88492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4a0c5dc-19f9-44c7-9342-04fd13ac10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Results for dataset A ðŸ”¹\n",
      "Decision Tree  : Accuracy = 0.8811 Â± 0.0437\n",
      "Random Forest  : Accuracy = 0.9088 Â± 0.0442\n",
      "SVM            : Accuracy = 0.8533 Â± 0.0794\n",
      "Neural Net     : Accuracy = 0.8252 Â± 0.0606\n",
      "\n",
      "ðŸ”¹ Results for dataset B ðŸ”¹\n",
      "Decision Tree  : Accuracy = 0.8079 Â± 0.0725\n",
      "Random Forest  : Accuracy = 0.8129 Â± 0.0330\n",
      "SVM            : Accuracy = 0.7930 Â± 0.0862\n",
      "Neural Net     : Accuracy = 0.7751 Â± 0.0703\n",
      "\n",
      "ðŸ”¹ Results for dataset C ðŸ”¹\n",
      "Decision Tree  : Accuracy = 0.6097 Â± 0.0615\n",
      "Random Forest  : Accuracy = 0.6958 Â± 0.0537\n",
      "SVM            : Accuracy = 0.6883 Â± 0.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net     : Accuracy = 0.6146 Â± 0.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(X_A_scaled, target, name=\"A\")\n",
    "evaluate_models(X_B_scaled, target, name=\"B\")\n",
    "evaluate_models(X_C_scaled, target, name=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a0191b3-cfc5-4c2d-8241-74bcac478160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, name=\"A\"):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(kernel='rbf', gamma='scale', random_state=42),\n",
    "        \"Neural Net\": MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42)\n",
    "    }\n",
    "\n",
    "    print(f\"\\nðŸ”¹ Results for dataset {name} ðŸ”¹\")\n",
    "    for model_name, model in models.items():\n",
    "        scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "        print(f\"{model_name:15}: Accuracy = {np.mean(scores):.4f} Â± {np.std(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1332dc58-9e2b-4e82-8026-05340bf76fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Results for dataset A ðŸ”¹\n",
      "Decision Tree  : Accuracy = 0.8811 Â± 0.0437\n",
      "Random Forest  : Accuracy = 0.9088 Â± 0.0442\n",
      "SVM            : Accuracy = 0.8533 Â± 0.0794\n",
      "Neural Net     : Accuracy = 0.8252 Â± 0.0606\n",
      "\n",
      "ðŸ”¹ Results for dataset B ðŸ”¹\n",
      "Decision Tree  : Accuracy = 0.8079 Â± 0.0725\n",
      "Random Forest  : Accuracy = 0.8129 Â± 0.0330\n",
      "SVM            : Accuracy = 0.7930 Â± 0.0862\n",
      "Neural Net     : Accuracy = 0.7751 Â± 0.0703\n",
      "\n",
      "ðŸ”¹ Results for dataset C ðŸ”¹\n",
      "Decision Tree  : Accuracy = 0.6097 Â± 0.0615\n",
      "Random Forest  : Accuracy = 0.6958 Â± 0.0537\n",
      "SVM            : Accuracy = 0.6883 Â± 0.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net     : Accuracy = 0.6146 Â± 0.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluate_models(X_A_scaled, target, name=\"A\")\n",
    "evaluate_models(X_B_scaled, target, name=\"B\")\n",
    "evaluate_models(X_C_scaled, target, name=\"C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8b2c600c-3fe8-40e0-a76d-f431169de538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def evaluate_models(X, y, name=\"A\"):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(kernel='rbf', gamma='scale', random_state=42),\n",
    "        \"Neural Net\": MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "    }\n",
    "\n",
    "    print(f\"\\nâ—† Results for dataset {name} â—†\")\n",
    "    for model_name, model in models.items():\n",
    "        scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "        print(f\"{model_name:20}: Accuracy = {np.mean(scores):.4f} Â± {np.std(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9362a64-13fe-4b7e-af27-19c071b1d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â—† Results for dataset A â—†\n",
      "Decision Tree       : Accuracy = 0.8811 Â± 0.0437\n",
      "Random Forest       : Accuracy = 0.9088 Â± 0.0442\n",
      "SVM                 : Accuracy = 0.8533 Â± 0.0794\n",
      "Neural Net          : Accuracy = 0.8252 Â± 0.0606\n",
      "Logistic Regression : Accuracy = 0.9037 Â± 0.0393\n",
      "\n",
      "â—† Results for dataset B â—†\n",
      "Decision Tree       : Accuracy = 0.8079 Â± 0.0725\n",
      "Random Forest       : Accuracy = 0.8129 Â± 0.0330\n",
      "SVM                 : Accuracy = 0.7930 Â± 0.0862\n",
      "Neural Net          : Accuracy = 0.7751 Â± 0.0703\n",
      "Logistic Regression : Accuracy = 0.8184 Â± 0.0775\n",
      "\n",
      "â—† Results for dataset C â—†\n",
      "Decision Tree       : Accuracy = 0.6097 Â± 0.0615\n",
      "Random Forest       : Accuracy = 0.6958 Â± 0.0537\n",
      "SVM                 : Accuracy = 0.6883 Â± 0.0637\n",
      "Neural Net          : Accuracy = 0.6171 Â± 0.0920\n",
      "Logistic Regression : Accuracy = 0.6961 Â± 0.0534\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(X_A_scaled, target, name=\"A\")\n",
    "evaluate_models(X_B_scaled, target, name=\"B\")\n",
    "evaluate_models(X_C_scaled, target, name=\"C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01dfcc-5c56-40b5-ac7c-c3df47fef0e3",
   "metadata": {},
   "source": [
    "Additional Contribution: Logistic Regression Model\n",
    "As part of my second contribution, I introduced a new classification algorithm: Logistic Regression.\n",
    "\n",
    "Logistic Regression is a simple yet powerful linear model commonly used for binary classification tasks. It provides a strong baseline for performance comparison and often performs surprisingly well on well-preprocessed datasets.\n",
    "\n",
    "To integrate it:\n",
    "\n",
    "I imported the model from sklearn.linear_model.\n",
    "\n",
    "I added it to the evaluation pipeline alongside Decision Tree, Random Forest, SVM, and Neural Net.\n",
    "\n",
    "I ensured a proper number of iterations (max_iter=1000) to avoid convergence issues.\n",
    "\n",
    "This addition allows us to compare a linear model with more complex algorithms and enriches the evaluation by broadening the diversity of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aec9cc-6299-409f-9f35-34fafe6c6145",
   "metadata": {},
   "source": [
    "Model Comparison\n",
    "After evaluating five classification algorithms (Decision Tree, Random Forest, SVM, Neural Network, and Logistic Regression) across datasets A, B, and C using 10-fold cross-validation, we observed the following insights:\n",
    "\n",
    "Random Forest consistently achieved the highest accuracy across all datasets, confirming its strength as a robust ensemble method.\n",
    "\n",
    "SVM and Neural Network delivered competitive performance, particularly in dataset A, but showed a drop in accuracy on dataset C, possibly due to data complexity or the need for further tuning.\n",
    "\n",
    "Decision Tree performed reasonably well but showed signs of overfitting compared to ensemble models.\n",
    "\n",
    "Logistic Regression, although simpler, showed decent performance and provided a valuable baseline. It is especially useful when interpretability and low computational cost are priorities.\n",
    "\n",
    "Overall, using a diverse set of models helped highlight the trade-offs between complexity, interpretability, and performance. The evaluation also underscores the importance of data quality and preprocessing, as model performance varied significantly across datasets A, B, and C."
   ]
>>>>>>> 0378e5c (Primer commit - notebook with models.)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.12.3"
=======
   "version": "3.12.7"
>>>>>>> 0378e5c (Primer commit - notebook with models.)
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
